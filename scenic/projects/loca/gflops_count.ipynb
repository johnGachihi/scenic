{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T20:08:26.668792Z",
     "start_time": "2025-05-01T20:08:26.666515Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 01:53:28.966013: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-02 01:53:28.966079: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-02 01:53:28.966105: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380b22f-7284-4cfd-bd35-0b0e7d12881c",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a0b5a8-7b71-4cae-8ed5-76aa2c3ea540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.loca_config import get_config\n",
    "\n",
    "config = get_config()\n",
    "config.batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3609c8-b744-4213-979f-e5fa1706b5c9",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f39f718-721a-4410-a7da-08237eb13a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/envs/flax/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2025-05-02 01:53:35.794154: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n",
      "WARNING:tensorflow:From /home/admin/anaconda3/envs/flax/lib/python3.10/site-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.counter(...)` instead.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:tensorflow:From /home/admin/john/scenic/scenic/dataset_lib/dataset_utils.py:671: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    }
   ],
   "source": [
    "from scenic.train_lib import train_utils\n",
    "import jax.numpy as jnp\n",
    "import loca_dataset\n",
    "import ops\n",
    "import jax\n",
    "\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.75'\n",
    "os.environ['TFDS_DATA_DIR'] = '/home/admin/john/data/tensorflow_datasets'\n",
    "\n",
    "rng = jax.random.key(42)\n",
    "data_rng, rng = jax.random.split(rng)\n",
    "\n",
    "dataset = train_utils.get_dataset(config, data_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59636db0-655f-4702-8101-cb78ba4418c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility\n",
    "def remove_batch_dim0(batch, debug=False):\n",
    "    # Remove dim 0. (Don't know where extra dim is added at 0)\n",
    "    for k, v in batch.items():\n",
    "        batch[k] = v.squeeze(0)\n",
    "        if debug:\n",
    "            print(f\"batch[{k}]: {batch[k].shape}\")\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db48ec1d-fe22-4240-b25c-6485be27607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_sample = next(dataset.train_iter)\n",
    "batched_sample = remove_batch_dim0(batched_sample)\n",
    "batched_sample = utils.prepare_input(batched_sample, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "825c6eed-305d-4a46-b57e-fd2bb9bd2f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_sample['reference'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3f4c3-140b-410f-a43f-ddc1690fd8ed",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4545e0e3-7f50-4384-a74b-ec0dd33ab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax.training import checkpoints\n",
    "import optax\n",
    "from scenic.train_lib import lr_schedules\n",
    "import vit\n",
    "import copy\n",
    "from scenic.common_lib import debug_utils\n",
    "import functools\n",
    "\n",
    "train_state = None\n",
    "\n",
    "def compute_loca_flops():\n",
    "    use_ema = config.apply_cluster_loss\n",
    "    use_pe = True if config.apply_cluster_loss else False\n",
    "    n_q_foc = config.dataset_configs.number_of_focal_queries\n",
    "\n",
    "    rng = jax.random.key(42)\n",
    "    dropout_rng, droptok_rng, changroup_rng = jax.random.split(rng, num=3)\n",
    "\n",
    "    model = vit.ViTLOCAModel(config, dataset.meta_data)\n",
    "\n",
    "    \n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    (params, state, num_trainable_params, gflops) = train_utils.initialize_model(\n",
    "        model_def=model.flax_model,\n",
    "        input_spec=[\n",
    "            (dataset.meta_data['input_shape'], dataset.meta_data.get('input_dtype', jnp.float32))],\n",
    "        config=config, rngs={'params': init_rng, 'changroup': init_rng}\n",
    "    )\n",
    "    variables = {'params': params, **state}\n",
    "\n",
    "    # flops for ref pass\n",
    "    r_flops = debug_utils.compute_flops(\n",
    "        flax_model_apply_fn=functools.partial(\n",
    "            model.flax_model.apply,\n",
    "            variables,\n",
    "            train=False,\n",
    "            debug=False,\n",
    "            rngs={'dropout': dropout_rng, 'droptok': droptok_rng, 'changroup': changroup_rng},\n",
    "    \n",
    "            seqlen=config.reference_seqlen,\n",
    "            seqlen_selection=config.reference_seqlen_selection,\n",
    "            drop_moment='late',\n",
    "        ),\n",
    "        input_spec=[(batched_sample['reference'].shape, jnp.float32)],\n",
    "        fuse_multiply_add=True,  # Default\n",
    "    )\n",
    "\n",
    "    # Get inputs for query passes\n",
    "    _, r_feat_targets, r_patch_features, r_idx_kept_tokens, _, r_idx_kept_groups  = model.flax_model.apply(\n",
    "        {'params': params},\n",
    "        batched_sample['reference'],\n",
    "        seqlen=config.reference_seqlen,\n",
    "        seqlen_selection=config.reference_seqlen_selection,\n",
    "        drop_moment='late',\n",
    "        train=False,\n",
    "        rngs={'dropout': dropout_rng, 'droptok': droptok_rng, 'changroup': changroup_rng}\n",
    "    )\n",
    "\n",
    "    # flops for q-rand pass\n",
    "    q_rand_flops = debug_utils.compute_flops(\n",
    "        flax_model_apply_fn=functools.partial(\n",
    "            model.flax_model.apply,\n",
    "            variables,\n",
    "            inputs_kv=r_patch_features,\n",
    "            inputs_kv_kept_groups=r_idx_kept_groups,\n",
    "            seqlen=config.query_max_seqlen,\n",
    "            use_pe=use_pe,\n",
    "            train=False,\n",
    "            debug=False,\n",
    "            rngs={'dropout': dropout_rng, 'droptok': droptok_rng, 'changroup': changroup_rng},\n",
    "        ),\n",
    "        input_spec=[(batched_sample['query0'].shape, jnp.float32)],\n",
    "        fuse_multiply_add=True,  # Default\n",
    "    )\n",
    "\n",
    "    # flops for q-foc pass\n",
    "    def model_wrapper(x):\n",
    "        return model.flax_model.apply(\n",
    "            variables,  # This is likely your {'params': params}\n",
    "            batched_sample['queries'],  # This will be the dummy input created by compute_flops\n",
    "            inputs_kv=jnp.tile(r_patch_features, (n_q_foc, 1, 1)),\n",
    "            inputs_kv_kept_groups=None if r_idx_kept_groups is None else jnp.tile(r_idx_kept_groups, (n_q_foc, 1)),\n",
    "            use_pe=use_pe,\n",
    "            train=False,\n",
    "            debug=False,\n",
    "            rngs={'dropout': dropout_rng, 'droptok': droptok_rng, 'changroup': changroup_rng},\n",
    "        )\n",
    "    \n",
    "    q_foc_flops = debug_utils.compute_flops(\n",
    "        flax_model_apply_fn=functools.partial(model_wrapper),\n",
    "        input_spec=[(batched_sample['queries'].shape, jnp.float32)],\n",
    "        fuse_multiply_add=True,  # Default\n",
    "    )\n",
    "\n",
    "    print(f'ref: {r_flops / 10**9:.3f}')\n",
    "    print(f'q_rand: {q_rand_flops / 10**9:.3f}')\n",
    "    print(f'q_foc: {q_foc_flops / 10**9:.3f}')\n",
    "\n",
    "    print(f'total: {(r_flops + q_rand_flops + q_foc_flops) / 10**9:.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e1a55-90d6-460c-a4eb-9214a8598718",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46191935-cd1e-4f17-8577-c06726f2818e",
   "metadata": {},
   "source": [
    "## LOCA Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bcf776-ecc7-485d-a86b-79b22f0b7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 0.239\n",
      "q_rand: 0.044\n",
      "q_foc: 0.719\n",
      "total: 1.002\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = None  # None, 'early_fuse_s1_to_rgbn', 'early_fuse_s1_to_all', 'early_concat_s2_and_s1, 'early_concat_s2_and_s1_early_fuse_dem', 'early_concat_s2_s1_dem'\n",
    "config.use_same_group_attn_mask = False\n",
    "config.sen2grouped = False\n",
    "config.sen2grouped_maintain_seqlen = False\n",
    "\n",
    "patch = 16\n",
    "reference_resolution = 224\n",
    "reference_patch_width = reference_resolution // patch\n",
    "query_rand_res = reference_resolution\n",
    "query_rand_mask_res = query_rand_res // patch  # Should be equal to patch width/height of rand query\n",
    "query_foc_res = 96\n",
    "query_foc_mask_res = query_foc_res // patch  # Should be equal to patch width/height of focal query\n",
    "n_queries = 10\n",
    "config.dataset_configs.pp_train = (\n",
    "  # Sentinel2 preprocessing.\n",
    "  'permute_channels_last(\"sentinel2\")' +\n",
    "\n",
    "  '|copy(\"sentinel2\", \"reference\")' +\n",
    "  f'|init_patch_matching_tracker({reference_patch_width}, \"target_mask\")' +\n",
    "  '|init_box_tracker(\"target_box\")' +\n",
    "  f'|cropflip_generatemask({reference_resolution}, 32, flip=False, inkey=(\"reference\", \"target_mask\", \"target_box\"), outkey=(\"reference\", \"target_mask\", \"target_box\"))' +\n",
    "  ''.join([f'|copy(\"sentinel2\", \"query{i}\")' for i in range(n_queries)]) +\n",
    "  f'|inception_crop_with_mask(({query_rand_res}, {query_rand_res}), 32, 100, ({query_rand_mask_res}, {query_rand_mask_res}), inkey=(\"query0\", \"target_mask\", \"target_box\"), outkey=(\"query0\", \"query0_mask\", \"query0_box\"))' +\n",
    "  ''.join([\n",
    "            f'|inception_crop_with_mask(({query_foc_res}, {query_foc_res}), 5, 32, ({query_foc_mask_res}, {query_foc_mask_res}), inkey=(\"query{i}\", \"target_mask\", \"target_box\"), outkey=(\"query{i}\", \"query{i}_mask\", \"query{i}_box\"))'\n",
    "            for i in range(1, n_queries)]) +\n",
    "  ''.join([f'|flip_with_mask(inkey=(\"query{i}\", \"query{i}_mask\"), outkey=(\"query{i}\", \"query{i}_mask\"))' for i in\n",
    "           range(n_queries)]) +\n",
    "  '|keep(\"reference\"' + ''.join(\n",
    "[f', \"query{i}\", \"query{i}_box\", \"query{i}_mask\"' for i in range(n_queries)]) + ', \"is_l2a\")')\n",
    "\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e253551-bfc5-494e-bb5c-1c691468cd2c",
   "metadata": {},
   "source": [
    "## With grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e22b52e-2d9d-4c51-b7a6-571b2c523fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 1.814\n",
      "q_rand: 0.271\n",
      "q_foc: 2.163\n",
      "total: 4.247\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = None  # None, 'early_fuse_s1_to_rgbn', 'early_fuse_s1_to_all', 'early_concat_s2_and_s1, 'early_concat_s2_and_s1_early_fuse_dem', 'early_concat_s2_s1_dem'\n",
    "config.use_same_group_attn_mask = False\n",
    "config.sen2grouped = True\n",
    "config.sen2grouped_maintain_seqlen = False\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11))\n",
    "\n",
    "patch = 16\n",
    "reference_resolution = 224\n",
    "reference_patch_width = reference_resolution // patch\n",
    "query_rand_res = reference_resolution\n",
    "query_rand_mask_res = query_rand_res // patch  # Should be equal to patch width/height of rand query\n",
    "query_foc_res = 96\n",
    "query_foc_mask_res = query_foc_res // patch  # Should be equal to patch width/height of focal query\n",
    "n_queries = 10\n",
    "config.dataset_configs.pp_train = (\n",
    "  # Sentinel2 preprocessing.\n",
    "  'permute_channels_last(\"sentinel2\")' +\n",
    "\n",
    "  '|copy(\"sentinel2\", \"reference\")' +\n",
    "  f'|init_patch_matching_tracker({reference_patch_width}, \"target_mask\")' +\n",
    "  '|init_box_tracker(\"target_box\")' +\n",
    "  f'|cropflip_generatemask({reference_resolution}, 32, flip=False, inkey=(\"reference\", \"target_mask\", \"target_box\"), outkey=(\"reference\", \"target_mask\", \"target_box\"))' +\n",
    "  ''.join([f'|copy(\"sentinel2\", \"query{i}\")' for i in range(n_queries)]) +\n",
    "  f'|inception_crop_with_mask(({query_rand_res}, {query_rand_res}), 32, 100, ({query_rand_mask_res}, {query_rand_mask_res}), inkey=(\"query0\", \"target_mask\", \"target_box\"), outkey=(\"query0\", \"query0_mask\", \"query0_box\"))' +\n",
    "  ''.join([\n",
    "            f'|inception_crop_with_mask(({query_foc_res}, {query_foc_res}), 5, 32, ({query_foc_mask_res}, {query_foc_mask_res}), inkey=(\"query{i}\", \"target_mask\", \"target_box\"), outkey=(\"query{i}\", \"query{i}_mask\", \"query{i}_box\"))'\n",
    "            for i in range(1, n_queries)]) +\n",
    "  ''.join([f'|flip_with_mask(inkey=(\"query{i}\", \"query{i}_mask\"), outkey=(\"query{i}\", \"query{i}_mask\"))' for i in\n",
    "           range(n_queries)]) +\n",
    "  '|keep(\"reference\"' + ''.join(\n",
    "[f', \"query{i}\", \"query{i}_box\", \"query{i}_mask\"' for i in range(n_queries)]) + ', \"is_l2a\")')\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2a1db-2b72-4771-84fd-03f82f84a072",
   "metadata": {},
   "source": [
    "## Channel grouping and Group sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93010b46-d1ce-4968-93b0-7d140fc824bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 0.240\n",
      "q_rand: 0.044\n",
      "q_foc: 0.719\n",
      "total: 1.003\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = None  # None, 'early_fuse_s1_to_rgbn', 'early_fuse_s1_to_all', 'early_concat_s2_and_s1, 'early_concat_s2_and_s1_early_fuse_dem', 'early_concat_s2_s1_dem'\n",
    "config.use_same_group_attn_mask = False\n",
    "config.sen2grouped = True\n",
    "config.sen2grouped_maintain_seqlen = True\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11))\n",
    "\n",
    "patch = 16\n",
    "reference_resolution = 224\n",
    "reference_patch_width = reference_resolution // patch\n",
    "query_rand_res = reference_resolution\n",
    "query_rand_mask_res = query_rand_res // patch  # Should be equal to patch width/height of rand query\n",
    "query_foc_res = 96\n",
    "query_foc_mask_res = query_foc_res // patch  # Should be equal to patch width/height of focal query\n",
    "n_queries = 10\n",
    "config.dataset_configs.pp_train = (\n",
    "  # Sentinel2 preprocessing.\n",
    "  'permute_channels_last(\"sentinel2\")' +\n",
    "\n",
    "  '|copy(\"sentinel2\", \"reference\")' +\n",
    "  f'|init_patch_matching_tracker({reference_patch_width}, \"target_mask\")' +\n",
    "  '|init_box_tracker(\"target_box\")' +\n",
    "  f'|cropflip_generatemask({reference_resolution}, 32, flip=False, inkey=(\"reference\", \"target_mask\", \"target_box\"), outkey=(\"reference\", \"target_mask\", \"target_box\"))' +\n",
    "  ''.join([f'|copy(\"sentinel2\", \"query{i}\")' for i in range(n_queries)]) +\n",
    "  f'|inception_crop_with_mask(({query_rand_res}, {query_rand_res}), 32, 100, ({query_rand_mask_res}, {query_rand_mask_res}), inkey=(\"query0\", \"target_mask\", \"target_box\"), outkey=(\"query0\", \"query0_mask\", \"query0_box\"))' +\n",
    "  ''.join([\n",
    "            f'|inception_crop_with_mask(({query_foc_res}, {query_foc_res}), 5, 32, ({query_foc_mask_res}, {query_foc_mask_res}), inkey=(\"query{i}\", \"target_mask\", \"target_box\"), outkey=(\"query{i}\", \"query{i}_mask\", \"query{i}_box\"))'\n",
    "            for i in range(1, n_queries)]) +\n",
    "  ''.join([f'|flip_with_mask(inkey=(\"query{i}\", \"query{i}_mask\"), outkey=(\"query{i}\", \"query{i}_mask\"))' for i in\n",
    "           range(n_queries)]) +\n",
    "  '|keep(\"reference\"' + ''.join(\n",
    "[f', \"query{i}\", \"query{i}_box\", \"query{i}_mask\"' for i in range(n_queries)]) + ', \"is_l2a\")')\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4cff5-7595-4da8-a101-5a1752fcd7f3",
   "metadata": {},
   "source": [
    "## Sen2 + Sen1 early summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103ccd6a-ef48-401c-be33-2d789e791d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering jdb:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(jdb)  x.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 588, 384)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(jdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering jdb:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(jdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering jdb:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(jdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering jdb:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(jdb)  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 1.814\n",
      "q_rand: 0.271\n",
      "q_foc: 2.163\n",
      "total: 4.247\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = 'early_fuse_s1_to_rgbn'\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11))\n",
    "config.sen2grouped_maintain_seqlen = False\n",
    "config.use_same_group_attn_mask = False\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c33f57-51a6-4021-8924-490b381e6893",
   "metadata": {},
   "source": [
    "## Sen2 + Sen1 early concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c02ced2-72f2-4ee0-b688-56dfc8aeb70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 4.848\n",
      "q_rand: 0.684\n",
      "q_foc: 3.622\n",
      "total: 9.154\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = 'early_concat_s2_and_s1'\n",
    "config.sen2grouped_maintain_seqlen = False\n",
    "config.use_same_group_attn_mask = False\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11),# sen2\n",
    "                           (12, 16), (13, 17))\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b49112f-2940-421f-8358-822a9d10aa9f",
   "metadata": {},
   "source": [
    "## Sen2 + Sen1 early concat with group sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8de95b-61d0-46da-bd19-f95a9a12f322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 0.240\n",
      "q_rand: 0.044\n",
      "q_foc: 0.720\n",
      "total: 1.004\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = 'early_concat_s2_and_s1'\n",
    "config.sen2grouped_maintain_seqlen = True\n",
    "config.use_same_group_attn_mask = False\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11),# sen2\n",
    "                           (12, 16), (13, 17))\n",
    "config.changroups_sampling_weights = (2, 2, 2, 3, 3)\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14277e5-aa0d-433a-b801-c4d978b0390f",
   "metadata": {},
   "source": [
    "## Sen2 + Sen1 early concat with group sampling and same-group attention masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72555fe3-81d1-46d8-afcc-786c866a9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 0.242\n",
      "q_rand: 0.044\n",
      "q_foc: 0.721\n",
      "total: 1.007\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = 'early_concat_s2_and_s1'\n",
    "config.sen2grouped_maintain_seqlen = True\n",
    "config.use_same_group_attn_mask = True\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11),# sen2\n",
    "                           (12, 16), (13, 17))\n",
    "config.changroups_sampling_weights = (2, 2, 2, 3, 3)\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced047e0-fcfe-454b-9bc9-456452c8d5ca",
   "metadata": {},
   "source": [
    "## Sen2 + Sen1 + DEM early concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6c1b862-f026-4838-a351-a4163835c6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 0.242\n",
      "q_rand: 0.044\n",
      "q_foc: 0.721\n",
      "total: 1.007\n"
     ]
    }
   ],
   "source": [
    "from configs.loca_config import get_config\n",
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = 'early_concat_s2_s1_dem'\n",
    "config.sen2grouped_maintain_seqlen = True\n",
    "config.use_same_group_attn_mask = True\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11),# sen2\n",
    "                           (12, 16), (13, 17),\n",
    "                        (20,))\n",
    "config.changroups_sampling_weights = (2, 2, 2, 3, 3, 6)\n",
    "\n",
    "compute_loca_flops()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a77986-3911-4c3a-9f08-386610e2e0ae",
   "metadata": {},
   "source": [
    "## Sen2 + Sen1 + DEM early concat ref masking 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "577f5320-4ede-4586-b820-24296635b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref: 0.242\n",
      "q_rand: 0.044\n",
      "q_foc: 0.721\n",
      "total: 1.007\n"
     ]
    }
   ],
   "source": [
    "config = get_config()\n",
    "config.batch_size = 1\n",
    "\n",
    "config.multimodal = 'early_concat_s2_s1_dem'\n",
    "config.sen2grouped_maintain_seqlen = True\n",
    "config.use_same_group_attn_mask = True\n",
    "config.sen2changroups = ((1, 2, 3, 7), (4, 5, 6, 8), (10, 11),# sen2\n",
    "                           (12, 16), (13, 17),\n",
    "                        (20,))\n",
    "config.changroups_sampling_weights = (2, 2, 2, 3, 3, 6)\n",
    "config.reference_seqlen = int(0.2 * config.n_ref_positions)\n",
    "\n",
    "compute_loca_flops()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
