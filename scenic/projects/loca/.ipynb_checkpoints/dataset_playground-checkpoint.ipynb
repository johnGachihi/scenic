{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T12:42:03.081609Z",
     "start_time": "2025-02-22T12:42:03.079484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1240526"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "data_root = Path('/home/admin/john/data/mmearth')\n",
    "\n",
    "splits_path = data_root / \"data_1M_v001_64_splits.json\"\n",
    "indices = json.load(open(splits_path, \"r\"))[\"train\"]\n",
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bf9d409df97db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "data_path = data_root / 'data_1M_v001_64.h5'\n",
    "data_full = h5py.File(data_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab8e381-b435-4cd7-806f-a3a39d764ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_info_path = data_root / 'data_1M_v001_64_tile_info.json'\n",
    "with open(tile_info_path, \"r\") as f:\n",
    "    tile_info = json.load(f)\n",
    "\n",
    "band_stats_path = data_root / 'data_1M_v001_64_band_stats.json'\n",
    "with open(band_stats_path, \"r\") as f:\n",
    "    band_stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a14e443d-614f-4144-b132-1aefd365c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_stats = band_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3ef374-983d-4c80-84e0-f323384115f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODALITIES = {\n",
    "    \"sentinel2\": [\n",
    "        \"B1\",\n",
    "        \"B2\",\n",
    "        \"B3\",\n",
    "        \"B4\",\n",
    "        \"B5\",\n",
    "        \"B6\",\n",
    "        \"B7\",\n",
    "        \"B8A\",\n",
    "        \"B8\",\n",
    "        \"B9\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ],\n",
    "    \"sentinel1\": \"all\",\n",
    "}\n",
    "\n",
    "MODALITIES_FULL = {\n",
    "    \"sentinel2\": [\n",
    "        \"B1\",\n",
    "        \"B2\",\n",
    "        \"B3\",\n",
    "        \"B4\",\n",
    "        \"B5\",\n",
    "        \"B6\",\n",
    "        \"B7\",\n",
    "        \"B8A\",\n",
    "        \"B8\",\n",
    "        \"B9\",\n",
    "        \"B10\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ],\n",
    "    \"sentinel2_cloudmask\": [\"QA60\"],\n",
    "    \"sentinel2_cloudprod\": [\"MSK_CLDPRB\"],\n",
    "    \"sentinel2_scl\": [\"SCL\"],\n",
    "    \"sentinel1\": [\n",
    "        \"asc_VV\",\n",
    "        \"asc_VH\",\n",
    "        \"asc_HH\",\n",
    "        \"asc_HV\",\n",
    "        \"desc_VV\",\n",
    "        \"desc_VH\",\n",
    "        \"desc_HH\",\n",
    "        \"desc_HV\",\n",
    "    ],\n",
    "    \"aster\": [\"elevation\", \"slope\"],\n",
    "    \"era5\": [\n",
    "        \"prev_month_avg_temp\",\n",
    "        \"prev_month_min_temp\",\n",
    "        \"prev_month_max_temp\",\n",
    "        \"prev_month_total_precip\",\n",
    "        \"curr_month_avg_temp\",\n",
    "        \"curr_month_min_temp\",\n",
    "        \"curr_month_max_temp\",\n",
    "        \"curr_month_total_precip\",\n",
    "        \"year_avg_temp\",\n",
    "        \"year_min_temp\",\n",
    "        \"year_max_temp\",\n",
    "        \"year_total_precip\",\n",
    "    ],\n",
    "    \"dynamic_world\": [\"landcover\"],\n",
    "    \"canopy_height_eth\": [\"height\", \"std\"],\n",
    "    \"lat\": [\"sin\", \"cos\"],\n",
    "    \"lon\": [\"sin\", \"cos\"],\n",
    "    \"biome\": [\"biome\"],\n",
    "    \"eco_region\": [\"eco_region\"],\n",
    "    \"month\": [\"sin_month\", \"cos_month\"],\n",
    "    \"esa_worldcover\": [\"map\"],\n",
    "}\n",
    "\n",
    "NO_DATA_VAL = {\n",
    "    \"sentinel2\": 0,\n",
    "    \"sentinel2_cloudmask\": 65535,\n",
    "    \"sentinel2_cloudprod\": 65535,\n",
    "    \"sentinel2_scl\": 255,\n",
    "    \"sentinel1\": float(\"-inf\"),\n",
    "    \"aster\": float(\"-inf\"),\n",
    "    \"canopy_height_eth\": 255,\n",
    "    \"dynamic_world\": 0,\n",
    "    \"esa_worldcover\": 255,\n",
    "    \"lat\": float(\"-inf\"),\n",
    "    \"lon\": float(\"-inf\"),\n",
    "    \"month\": float(\"-inf\"),\n",
    "    \"era5\": float(\"inf\"),\n",
    "    \"biome\": 255,\n",
    "    \"eco_region\": 65535,\n",
    "}\n",
    "\n",
    "modalities_full = MODALITIES_FULL\n",
    "modalities = MODALITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8abfa01e-6273-4971-8d48-9e336bfc9e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modality sentinel2\n",
      "modality_idx [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12]\n",
      "data (12, 64, 64) [1627 1625 1629 1640 1650]\n",
      "data (12, 64, 64) [-0.15649307 -0.1578088  -0.15517734 -0.14794082 -0.14136217]\n",
      "\n",
      "modality sentinel1\n",
      "modality_idx [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "data (8, 64, 64) [-7.246237  -8.437068  -9.1128235 -9.794962  -9.71821  ]\n",
      "data (8, 64, 64) [0.86320915 0.6310232  0.49926571 0.36626369 0.38122859]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12, 64, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "idx = 0\n",
    "return_dict = OrderedDict()\n",
    "name = data_full['metadata'][indices[idx]][0].decode(\"utf-8\")\n",
    "l2a = tile_info[name][\"S2_type\"] == \"l2a\"\n",
    "\n",
    "for modality in modalities.keys():\n",
    "    print(\"modality\", modality)\n",
    "    if modalities[modality] == \"all\":\n",
    "        modality_idx = [i for i in range(len(modalities_full[modality]))]\n",
    "    else:\n",
    "        modality_idx = [\n",
    "            modalities_full[modality].index(m)\n",
    "            for m in modalities[modality]\n",
    "        ]\n",
    "    print('modality_idx', modality_idx)\n",
    "\n",
    "    data = data_full[modality][indices[idx], modality_idx, ...]\n",
    "    data = np.array(data)\n",
    "    print('data', data.shape, data[0, 0, :5])\n",
    "\n",
    "    if modality == \"sentinel2\":\n",
    "        modality_ = \"sentinel2_l2a\" if l2a else \"sentinel2_l1c\"\n",
    "    else:\n",
    "        modality_ = modality\n",
    "\n",
    "    if modality not in [\"biome\", \"eco_region\", \"dynamic_world\", \"esa_worldcover\"]:\n",
    "        means = np.array(norm_stats[modality_][\"mean\"])[modality_idx]\n",
    "        stds = np.array(norm_stats[modality_][\"std\"])[modality_idx]\n",
    "        if modality in [\"era5\", \"lat\", \"lon\", \"month\"]:\n",
    "            # single value mean and std\n",
    "            data = (data - means) / stds\n",
    "        else:\n",
    "            # single value mean and std for each band\n",
    "            data = (data - means[:, None, None]) / stds[:, None, None]\n",
    "    print('data', data.shape, data[0, 0, :5])\n",
    "\n",
    "    data = (\n",
    "        np.where(data == NO_DATA_VAL[modality], np.nan, data)\n",
    "        if modality != \"dynamic_world\"\n",
    "        else data\n",
    "    )\n",
    "\n",
    "    data = data.astype(np.dtype(\"float32\"))\n",
    "\n",
    "    return_dict[modality] = data\n",
    "\n",
    "    print()\n",
    "\n",
    "return_dict['sentinel2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e41db-42b4-498b-9623-026812660d62",
   "metadata": {},
   "source": [
    "# TFDS Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e02a3aa-1de0-4b15-ad2c-65d3cc648f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODALITIES_FULL = {\n",
    "    \"sentinel2\": [\n",
    "        \"B1\",\n",
    "        \"B2\",\n",
    "        \"B3\",\n",
    "        \"B4\",\n",
    "        \"B5\",\n",
    "        \"B6\",\n",
    "        \"B7\",\n",
    "        \"B8A\",\n",
    "        \"B8\",\n",
    "        \"B9\",\n",
    "        \"B10\",\n",
    "        \"B11\",\n",
    "        \"B12\",\n",
    "    ],\n",
    "    \"sentinel2_cloudmask\": [\"QA60\"],\n",
    "    \"sentinel2_cloudprod\": [\"MSK_CLDPRB\"],\n",
    "    \"sentinel2_scl\": [\"SCL\"],\n",
    "    \"sentinel1\": [\n",
    "        \"asc_VV\",\n",
    "        \"asc_VH\",\n",
    "        \"asc_HH\",\n",
    "        \"asc_HV\",\n",
    "        \"desc_VV\",\n",
    "        \"desc_VH\",\n",
    "        \"desc_HH\",\n",
    "        \"desc_HV\",\n",
    "    ],\n",
    "    \"aster\": [\"elevation\", \"slope\"],\n",
    "    \"era5\": [\n",
    "        \"prev_month_avg_temp\",\n",
    "        \"prev_month_min_temp\",\n",
    "        \"prev_month_max_temp\",\n",
    "        \"prev_month_total_precip\",\n",
    "        \"curr_month_avg_temp\",\n",
    "        \"curr_month_min_temp\",\n",
    "        \"curr_month_max_temp\",\n",
    "        \"curr_month_total_precip\",\n",
    "        \"year_avg_temp\",\n",
    "        \"year_min_temp\",\n",
    "        \"year_max_temp\",\n",
    "        \"year_total_precip\",\n",
    "    ],\n",
    "    \"dynamic_world\": [\"landcover\"],\n",
    "    \"canopy_height_eth\": [\"height\", \"std\"],\n",
    "    \"lat\": [\"sin\", \"cos\"],\n",
    "    \"lon\": [\"sin\", \"cos\"],\n",
    "    \"biome\": [\"biome\"],\n",
    "    \"eco_region\": [\"eco_region\"],\n",
    "    \"month\": [\"sin_month\", \"cos_month\"],\n",
    "    \"esa_worldcover\": [\"map\"],\n",
    "}\n",
    "\n",
    "NO_DATA_VAL = {\n",
    "    \"sentinel2\": 0,\n",
    "    \"sentinel2_cloudmask\": 65535,\n",
    "    \"sentinel2_cloudprod\": 65535,\n",
    "    \"sentinel2_scl\": 255,\n",
    "    \"sentinel1\": float(\"-inf\"),\n",
    "    \"aster\": float(\"-inf\"),\n",
    "    \"canopy_height_eth\": 255,\n",
    "    \"dynamic_world\": 0,\n",
    "    \"esa_worldcover\": 255,\n",
    "    \"lat\": float(\"-inf\"),\n",
    "    \"lon\": float(\"-inf\"),\n",
    "    \"month\": float(\"-inf\"),\n",
    "    \"era5\": float(\"inf\"),\n",
    "    \"biome\": 255,\n",
    "    \"eco_region\": 65535,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb5c978c-e551-493d-8f52-2dfb7da7bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class MMEarthBuilder(tfds.core.GeneratorBasedBuilder):\n",
    "    VERSION = tfds.core.Version('0.0.1')\n",
    "    \n",
    "    def __init__(self, modalities: dict, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.modalities = modalities\n",
    "\n",
    "    def _info(self):\n",
    "        return tfds.core.DatasetInfo(\n",
    "            builder=self,\n",
    "            features=tfds.features.FeaturesDict({\n",
    "                'sentinel2': tfds.features.Tensor(shape=(12, 64, 64), dtype=np.dtype(\"float32\")),\n",
    "                'sentinel1': tfds.features.Tensor(shape=(8, 64, 64), dtype=np.dtype(\"float32\")),\n",
    "                'id': tfds.features.Text(),\n",
    "            }),\n",
    "        )\n",
    "\n",
    "    def _split_generators(self, dl_manager):\n",
    "        data_root = Path('/home/admin/john/data/mmearth')\n",
    "\n",
    "        # Full data\n",
    "        data_path = data_root / 'data_1M_v001_64.h5'\n",
    "        data_full = h5py.File(data_path, 'r')\n",
    "\n",
    "        # Split indices\n",
    "        splits_path = data_root / 'data_1M_v001_64_splits.json'\n",
    "        with open(splits_path, \"r\") as f:\n",
    "            indices = json.load(f)[\"train\"][:10000]\n",
    "\n",
    "        # Tile info\n",
    "        tile_info_path = data_root / 'data_1M_v001_64_tile_info.json'\n",
    "        with open(tile_info_path, \"r\") as f:\n",
    "            tile_info = json.load(f)\n",
    "\n",
    "        # Band norm stats\n",
    "        band_stats_path = data_root / 'data_1M_v001_64_band_stats.json'\n",
    "        with open(band_stats_path, \"r\") as f:\n",
    "            norm_stats = json.load(f)\n",
    "        \n",
    "        return {\n",
    "            'train': self._generate_examples(data_full, indices, tile_info, norm_stats)\n",
    "        }\n",
    "\n",
    "    def _generate_examples(self, data_full, indices, tile_info, norm_stats):\n",
    "        for idx in indices:\n",
    "            return_dict = OrderedDict()\n",
    "            name = data_full['metadata'][idx][0].decode(\"utf-8\")\n",
    "            l2a = tile_info[name][\"S2_type\"] == \"l2a\"\n",
    "\n",
    "            for modality in self.modalities.keys():\n",
    "                # Get band indices\n",
    "                if self.modalities[modality] == \"all\":\n",
    "                    modality_idx = [i for i in range(len(MODALITIES_FULL[modality]))]\n",
    "                else:\n",
    "                    modality_idx = [MODALITIES_FULL[modality].index(m) for m in self.modalities[modality]]\n",
    "\n",
    "                # Get data\n",
    "                data = data_full[modality][idx, modality_idx, ...]\n",
    "                data = np.array(data)\n",
    "\n",
    "                # inside the band_stats, the name for sentinel2 is sentinel2_l1c or sentinel2_l2a\n",
    "                if modality == \"sentinel2\":\n",
    "                    modality_ = \"sentinel2_l2a\" if l2a else \"sentinel2_l1c\"\n",
    "                else:\n",
    "                    modality_ = modality\n",
    "\n",
    "                means = np.array(norm_stats[modality_][\"mean\"])[modality_idx]\n",
    "                stds = np.array(norm_stats[modality_][\"std\"])[modality_idx]\n",
    "                data = (data - means[:, None, None]) / stds[:, None, None]  # Why the `None`s\n",
    "\n",
    "                # converting the nodata values to nan to keep everything consistent\n",
    "                data = (\n",
    "                    np.where(data == NO_DATA_VAL[modality], np.nan, data)\n",
    "                    if modality != \"dynamic_world\"\n",
    "                    else data\n",
    "                )\n",
    "\n",
    "                data = data.astype(np.dtype(\"float32\"))\n",
    "\n",
    "                return_dict[modality] = data\n",
    "\n",
    "            return_dict[\"id\"] = name\n",
    "\n",
    "            yield name, return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b6b643-85e9-4236-8ccb-7c1fc38397a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 20:33:30.465863: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-22 20:33:30.466016: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-22 20:33:30.466046: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 20:33:30.482043: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-22 20:33:33.201618: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/admin/tensorflow_datasets/mm_earth_builder/0.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/anaconda3/envs/flax/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]\n",
      "\u001b[Aerating train examples...: 0 examples [00:00, ? examples/s]\n",
      "\u001b[Aerating train examples...: 49 examples [00:01, 48.52 examples/s]\n",
      "\u001b[Aerating train examples...: 99 examples [00:02, 49.09 examples/s]\n",
      "\u001b[Aerating train examples...: 149 examples [00:03, 49.10 examples/s]\n",
      "\u001b[Aerating train examples...: 199 examples [00:04, 48.69 examples/s]\n",
      "\u001b[Aerating train examples...: 248 examples [00:05, 48.71 examples/s]\n",
      "\u001b[Aerating train examples...: 297 examples [00:06, 48.43 examples/s]\n",
      "\u001b[Aerating train examples...: 346 examples [00:07, 48.32 examples/s]\n",
      "\u001b[Aerating train examples...: 395 examples [00:08, 48.51 examples/s]\n",
      "\u001b[Aerating train examples...: 444 examples [00:09, 48.18 examples/s]\n",
      "\u001b[Aerating train examples...: 493 examples [00:10, 48.25 examples/s]\n",
      "\u001b[Aerating train examples...: 542 examples [00:11, 48.16 examples/s]\n",
      "\u001b[Aerating train examples...: 591 examples [00:12, 48.10 examples/s]\n",
      "\u001b[Aerating train examples...: 640 examples [00:13, 48.24 examples/s]\n",
      "\u001b[Aerating train examples...: 689 examples [00:14, 48.12 examples/s]\n",
      "\u001b[Aerating train examples...: 738 examples [00:15, 48.27 examples/s]\n",
      "\u001b[Aerating train examples...: 787 examples [00:16, 48.18 examples/s]\n",
      "\u001b[Aerating train examples...: 836 examples [00:17, 48.12 examples/s]\n",
      "\u001b[Aerating train examples...: 885 examples [00:18, 48.38 examples/s]\n",
      "\u001b[Aerating train examples...: 935 examples [00:19, 48.60 examples/s]\n",
      "\u001b[Aerating train examples...: 986 examples [00:20, 49.04 examples/s]\n",
      "\u001b[Aerating train examples...: 1036 examples [00:21, 49.19 examples/s]\n",
      "\u001b[Aerating train examples...: 1086 examples [00:22, 49.09 examples/s]\n",
      "\u001b[Aerating train examples...: 1136 examples [00:23, 49.16 examples/s]\n",
      "\u001b[Aerating train examples...: 1186 examples [00:24, 48.66 examples/s]\n",
      "\u001b[Aerating train examples...: 1235 examples [00:25, 48.67 examples/s]\n",
      "\u001b[Aerating train examples...: 1284 examples [00:26, 48.70 examples/s]\n",
      "\u001b[Aerating train examples...: 1333 examples [00:27, 48.64 examples/s]\n",
      "\u001b[Aerating train examples...: 1382 examples [00:28, 48.66 examples/s]\n",
      "\u001b[Aerating train examples...: 1432 examples [00:29, 48.85 examples/s]\n",
      "\u001b[Aerating train examples...: 1482 examples [00:30, 48.99 examples/s]\n",
      "\u001b[Aerating train examples...: 1532 examples [00:31, 49.02 examples/s]\n",
      "\u001b[Aerating train examples...: 1582 examples [00:32, 48.96 examples/s]\n",
      "\u001b[Aerating train examples...: 1632 examples [00:33, 49.05 examples/s]\n",
      "\u001b[Aerating train examples...: 1682 examples [00:34, 49.13 examples/s]\n",
      "\u001b[Aerating train examples...: 1732 examples [00:35, 48.49 examples/s]\n",
      "\u001b[Aerating train examples...: 1781 examples [00:36, 48.49 examples/s]\n",
      "\u001b[Aerating train examples...: 1830 examples [00:37, 48.25 examples/s]\n",
      "\u001b[Aerating train examples...: 1880 examples [00:38, 48.54 examples/s]\n",
      "\u001b[Aerating train examples...: 1929 examples [00:39, 48.66 examples/s]\n",
      "\u001b[Aerating train examples...: 1979 examples [00:40, 48.85 examples/s]\n",
      "\u001b[Aerating train examples...: 2028 examples [00:41, 48.79 examples/s]\n",
      "\u001b[Aerating train examples...: 2077 examples [00:42, 48.75 examples/s]\n",
      "\u001b[Aerating train examples...: 2126 examples [00:43, 48.77 examples/s]\n",
      "\u001b[Aerating train examples...: 2177 examples [00:44, 49.20 examples/s]\n",
      "\u001b[Aerating train examples...: 2229 examples [00:45, 49.89 examples/s]\n",
      "\u001b[Aerating train examples...: 2283 examples [00:46, 50.94 examples/s]\n",
      "\u001b[Aerating train examples...: 2338 examples [00:47, 51.95 examples/s]\n",
      "\u001b[Aerating train examples...: 2392 examples [00:48, 52.37 examples/s]\n",
      "\u001b[Aerating train examples...: 2445 examples [00:49, 51.10 examples/s]\n",
      "\u001b[Aerating train examples...: 2497 examples [00:50, 50.45 examples/s]\n",
      "\u001b[Aerating train examples...: 2548 examples [00:52, 49.58 examples/s]\n",
      "\u001b[Aerating train examples...: 2599 examples [00:53, 49.73 examples/s]\n",
      "\u001b[Aerating train examples...: 2649 examples [00:54, 49.60 examples/s]\n",
      "\u001b[Aerating train examples...: 2700 examples [00:55, 49.96 examples/s]\n",
      "\u001b[Aerating train examples...: 2752 examples [00:56, 50.54 examples/s]\n",
      "\u001b[Aerating train examples...: 2805 examples [00:57, 51.11 examples/s]\n",
      "\u001b[Aerating train examples...: 2858 examples [00:58, 51.64 examples/s]\n",
      "\u001b[Aerating train examples...: 2913 examples [00:59, 52.54 examples/s]\n",
      "\u001b[Aerating train examples...: 2967 examples [01:00, 52.94 examples/s]\n",
      "\u001b[Aerating train examples...: 3021 examples [01:01, 53.14 examples/s]\n",
      "\u001b[Aerating train examples...: 3075 examples [01:02, 53.23 examples/s]\n",
      "\u001b[Aerating train examples...: 3129 examples [01:03, 53.25 examples/s]\n",
      "\u001b[Aerating train examples...: 3183 examples [01:04, 53.41 examples/s]\n",
      "\u001b[Aerating train examples...: 3237 examples [01:05, 43.18 examples/s]\n",
      "\u001b[Aerating train examples...: 3291 examples [01:06, 45.82 examples/s]\n",
      "\u001b[Aerating train examples...: 3345 examples [01:07, 47.84 examples/s]\n",
      "\u001b[Aerating train examples...: 3395 examples [01:08, 48.26 examples/s]\n",
      "\u001b[Aerating train examples...: 3449 examples [01:09, 49.70 examples/s]\n",
      "\u001b[Aerating train examples...: 3502 examples [01:10, 50.60 examples/s]\n",
      "\u001b[Aerating train examples...: 3556 examples [01:11, 51.57 examples/s]\n",
      "\u001b[Aerating train examples...: 3610 examples [01:12, 52.20 examples/s]\n",
      "\u001b[Aerating train examples...: 3663 examples [01:14, 48.83 examples/s]\n",
      "\u001b[Aerating train examples...: 3713 examples [01:15, 44.51 examples/s]\n",
      "\u001b[Aerating train examples...: 3766 examples [01:16, 46.60 examples/s]\n",
      "\u001b[Aerating train examples...: 3818 examples [01:17, 48.07 examples/s]\n",
      "\u001b[Aerating train examples...: 3871 examples [01:18, 49.39 examples/s]\n",
      "\u001b[Aerating train examples...: 3925 examples [01:19, 50.55 examples/s]\n",
      "\u001b[Aerating train examples...: 3978 examples [01:20, 51.00 examples/s]\n",
      "\u001b[Aerating train examples...: 4031 examples [01:21, 51.37 examples/s]\n",
      "\u001b[Aerating train examples...: 4085 examples [01:22, 52.00 examples/s]\n",
      "\u001b[Aerating train examples...: 4139 examples [01:23, 52.51 examples/s]\n",
      "\u001b[Aerating train examples...: 4193 examples [01:24, 52.91 examples/s]\n",
      "\u001b[Aerating train examples...: 4247 examples [01:25, 52.94 examples/s]\n",
      "\u001b[Aerating train examples...: 4301 examples [01:26, 52.71 examples/s]\n",
      "\u001b[Aerating train examples...: 4354 examples [01:27, 51.85 examples/s]\n",
      "\u001b[Aerating train examples...: 4406 examples [01:28, 50.71 examples/s]\n",
      "\u001b[Aerating train examples...: 4457 examples [01:29, 49.74 examples/s]\n",
      "\u001b[Aerating train examples...: 4507 examples [01:30, 49.16 examples/s]\n",
      "\u001b[Aerating train examples...: 4557 examples [01:32, 48.79 examples/s]\n",
      "\u001b[Aerating train examples...: 4606 examples [01:33, 48.51 examples/s]\n",
      "\u001b[Aerating train examples...: 4655 examples [01:34, 48.49 examples/s]\n",
      "\u001b[Aerating train examples...: 4704 examples [01:35, 48.44 examples/s]\n",
      "\u001b[Aerating train examples...: 4753 examples [01:36, 47.95 examples/s]\n",
      "\u001b[Aerating train examples...: 4801 examples [01:37, 47.92 examples/s]\n",
      "\u001b[Aerating train examples...: 4849 examples [01:38, 47.85 examples/s]\n",
      "\u001b[Aerating train examples...: 4897 examples [01:39, 46.07 examples/s]\n",
      "\u001b[Aerating train examples...: 4944 examples [01:40, 45.81 examples/s]\n",
      "\u001b[Aerating train examples...: 4990 examples [01:41, 45.77 examples/s]\n",
      "\u001b[Aerating train examples...: 5038 examples [01:42, 46.26 examples/s]\n",
      "\u001b[Aerating train examples...: 5087 examples [01:43, 46.83 examples/s]\n",
      "\u001b[Aerating train examples...: 5135 examples [01:44, 47.02 examples/s]\n",
      "\u001b[Aerating train examples...: 5184 examples [01:45, 47.33 examples/s]\n",
      "\u001b[Aerating train examples...: 5232 examples [01:46, 47.26 examples/s]\n",
      "\u001b[Aerating train examples...: 5281 examples [01:47, 47.54 examples/s]\n",
      "\u001b[Aerating train examples...: 5329 examples [01:48, 47.52 examples/s]\n",
      "\u001b[Aerating train examples...: 5378 examples [01:49, 47.68 examples/s]\n",
      "\u001b[Aerating train examples...: 5426 examples [01:50, 47.77 examples/s]\n",
      "\u001b[Aerating train examples...: 5474 examples [01:51, 46.07 examples/s]\n",
      "\u001b[Aerating train examples...: 5522 examples [01:52, 46.57 examples/s]\n",
      "\u001b[Aerating train examples...: 5570 examples [01:53, 46.98 examples/s]\n",
      "\u001b[Aerating train examples...: 5618 examples [01:54, 47.21 examples/s]\n",
      "\u001b[Aerating train examples...: 5666 examples [01:55, 47.39 examples/s]\n",
      "\u001b[Aerating train examples...: 5714 examples [01:56, 45.68 examples/s]\n",
      "\u001b[Aerating train examples...: 5762 examples [01:57, 46.14 examples/s]\n",
      "\u001b[Aerating train examples...: 5811 examples [01:58, 46.72 examples/s]\n",
      "\u001b[Aerating train examples...: 5859 examples [01:59, 46.91 examples/s]\n",
      "\u001b[Aerating train examples...: 5907 examples [02:00, 47.08 examples/s]\n",
      "\u001b[Aerating train examples...: 5955 examples [02:01, 45.85 examples/s]\n",
      "\u001b[Aerating train examples...: 6001 examples [02:02, 45.43 examples/s]\n",
      "\u001b[Aerating train examples...: 6049 examples [02:03, 45.99 examples/s]\n",
      "\u001b[Aerating train examples...: 6097 examples [02:04, 46.40 examples/s]\n",
      "\u001b[Aerating train examples...: 6146 examples [02:05, 46.88 examples/s]\n",
      "\u001b[Aerating train examples...: 6194 examples [02:06, 46.97 examples/s]\n",
      "\u001b[Aerating train examples...: 6241 examples [02:08, 45.88 examples/s]\n",
      "\u001b[Aerating train examples...: 6289 examples [02:09, 46.20 examples/s]\n",
      "\u001b[Aerating train examples...: 6337 examples [02:10, 46.45 examples/s]\n",
      "\u001b[Aerating train examples...: 6385 examples [02:11, 46.75 examples/s]\n",
      "\u001b[Aerating train examples...: 6433 examples [02:12, 46.84 examples/s]\n",
      "\u001b[Aerating train examples...: 6480 examples [02:13, 45.28 examples/s]\n",
      "\u001b[Aerating train examples...: 6528 examples [02:14, 45.82 examples/s]\n",
      "\u001b[Aerating train examples...: 6576 examples [02:15, 46.30 examples/s]\n",
      "\u001b[Aerating train examples...: 6623 examples [02:16, 46.43 examples/s]\n",
      "\u001b[Aerating train examples...: 6671 examples [02:17, 46.83 examples/s]\n",
      "\u001b[Aerating train examples...: 6718 examples [02:18, 46.35 examples/s]\n",
      "\u001b[Aerating train examples...: 6766 examples [02:19, 46.73 examples/s]\n",
      "\u001b[Aerating train examples...: 6814 examples [02:20, 46.99 examples/s]\n",
      "\u001b[Aerating train examples...: 6862 examples [02:21, 47.18 examples/s]\n",
      "\u001b[Aerating train examples...: 6910 examples [02:22, 47.31 examples/s]\n",
      "\u001b[Aerating train examples...: 6958 examples [02:23, 46.96 examples/s]\n",
      "\u001b[Aerating train examples...: 7007 examples [02:24, 47.30 examples/s]\n",
      "\u001b[Aerating train examples...: 7055 examples [02:25, 47.29 examples/s]\n",
      "\u001b[Aerating train examples...: 7103 examples [02:26, 47.45 examples/s]\n",
      "\u001b[Aerating train examples...: 7151 examples [02:27, 47.47 examples/s]\n",
      "\u001b[Aerating train examples...: 7199 examples [02:28, 47.20 examples/s]\n",
      "\u001b[Aerating train examples...: 7247 examples [02:29, 47.34 examples/s]\n",
      "\u001b[Aerating train examples...: 7295 examples [02:30, 47.43 examples/s]\n",
      "\u001b[Aerating train examples...: 7344 examples [02:31, 47.75 examples/s]\n",
      "\u001b[Aerating train examples...: 7392 examples [02:32, 47.57 examples/s]\n",
      "\u001b[Aerating train examples...: 7440 examples [02:33, 47.32 examples/s]\n",
      "\u001b[Aerating train examples...: 7488 examples [02:34, 47.26 examples/s]\n",
      "\u001b[Aerating train examples...: 7536 examples [02:35, 47.44 examples/s]\n",
      "\u001b[Aerating train examples...: 7584 examples [02:36, 47.51 examples/s]\n",
      "\u001b[Aerating train examples...: 7632 examples [02:37, 47.53 examples/s]\n",
      "\u001b[Aerating train examples...: 7680 examples [02:38, 47.30 examples/s]\n",
      "\u001b[Aerating train examples...: 7728 examples [02:39, 47.25 examples/s]\n",
      "\u001b[Aerating train examples...: 7777 examples [02:40, 47.53 examples/s]\n",
      "\u001b[Aerating train examples...: 7825 examples [02:41, 47.52 examples/s]\n",
      "\u001b[Aerating train examples...: 7873 examples [02:42, 47.62 examples/s]\n",
      "\u001b[Aerating train examples...: 7921 examples [02:43, 47.56 examples/s]\n",
      "\u001b[Aerating train examples...: 7969 examples [02:44, 47.34 examples/s]\n",
      "\u001b[Aerating train examples...: 8017 examples [02:45, 47.51 examples/s]\n",
      "\u001b[Aerating train examples...: 8065 examples [02:46, 47.49 examples/s]\n",
      "\u001b[Aerating train examples...: 8114 examples [02:47, 47.77 examples/s]\n",
      "\u001b[Aerating train examples...: 8162 examples [02:48, 47.74 examples/s]\n",
      "\u001b[Aerating train examples...: 8210 examples [02:49, 47.37 examples/s]\n",
      "\u001b[Aerating train examples...: 8258 examples [02:50, 47.49 examples/s]\n",
      "\u001b[Aerating train examples...: 8306 examples [02:51, 47.46 examples/s]\n",
      "\u001b[Aerating train examples...: 8354 examples [02:52, 47.43 examples/s]\n",
      "\u001b[Aerating train examples...: 8402 examples [02:53, 47.39 examples/s]\n",
      "\u001b[Aerating train examples...: 8450 examples [02:54, 47.39 examples/s]\n",
      "\u001b[Aerating train examples...: 8498 examples [02:55, 47.23 examples/s]\n",
      "\u001b[Aerating train examples...: 8546 examples [02:56, 47.26 examples/s]\n",
      "\u001b[Aerating train examples...: 8594 examples [02:57, 47.41 examples/s]\n",
      "\u001b[Aerating train examples...: 8643 examples [02:58, 47.72 examples/s]\n",
      "\u001b[Aerating train examples...: 8692 examples [02:59, 48.03 examples/s]\n",
      "\u001b[Aerating train examples...: 8744 examples [03:00, 49.01 examples/s]\n",
      "\u001b[Aerating train examples...: 8797 examples [03:01, 50.05 examples/s]\n",
      "\u001b[Aerating train examples...: 8848 examples [03:02, 49.62 examples/s]\n",
      "\u001b[Aerating train examples...: 8898 examples [03:04, 49.15 examples/s]\n",
      "\u001b[Aerating train examples...: 8948 examples [03:05, 48.19 examples/s]\n",
      "\u001b[Aerating train examples...: 8997 examples [03:06, 48.28 examples/s]\n",
      "\u001b[Aerating train examples...: 9046 examples [03:07, 47.71 examples/s]\n",
      "\u001b[Aerating train examples...: 9094 examples [03:08, 47.75 examples/s]\n",
      "\u001b[Aerating train examples...: 9142 examples [03:09, 47.52 examples/s]\n",
      "\u001b[Aerating train examples...: 9190 examples [03:10, 46.90 examples/s]\n",
      "\u001b[Aerating train examples...: 9237 examples [03:11, 46.93 examples/s]\n",
      "\u001b[Aerating train examples...: 9284 examples [03:12, 46.90 examples/s]\n",
      "\u001b[Aerating train examples...: 9333 examples [03:13, 47.26 examples/s]\n",
      "\u001b[Aerating train examples...: 9381 examples [03:14, 47.17 examples/s]\n",
      "\u001b[Aerating train examples...: 9429 examples [03:15, 46.95 examples/s]\n",
      "\u001b[Aerating train examples...: 9476 examples [03:16, 46.86 examples/s]\n",
      "\u001b[Aerating train examples...: 9524 examples [03:17, 47.16 examples/s]\n",
      "\u001b[Aerating train examples...: 9572 examples [03:18, 47.29 examples/s]\n",
      "\u001b[Aerating train examples...: 9620 examples [03:19, 47.38 examples/s]\n",
      "\u001b[Aerating train examples...: 9668 examples [03:20, 47.30 examples/s]\n",
      "\u001b[Aerating train examples...: 9716 examples [03:21, 47.28 examples/s]\n",
      "\u001b[Aerating train examples...: 9765 examples [03:22, 47.70 examples/s]\n",
      "\u001b[Aerating train examples...: 9813 examples [03:23, 47.51 examples/s]\n",
      "\u001b[Aerating train examples...: 9861 examples [03:24, 47.48 examples/s]\n",
      "\u001b[Aerating train examples...: 9909 examples [03:25, 47.06 examples/s]\n",
      "\u001b[Aerating train examples...: 9957 examples [03:26, 46.99 examples/s]\n",
      "\u001b[A                                                                  \n",
      "\u001b[Affling /home/admin/tensorflow_datasets/mm_earth_builder/incomplete.MQSPB6_0.0.1/mm_earth_builder-train.tfrecord*...:   0%|          | 0/10000 [00:00<?, ? examples/s]\n",
      "\u001b[Affling /home/admin/tensorflow_datasets/mm_earth_builder/incomplete.MQSPB6_0.0.1/mm_earth_builder-train.tfrecord*...:  21%|██        | 2101/10000 [00:01<00:03, 2097.95 examples/s]\n",
      "\u001b[Affling /home/admin/tensorflow_datasets/mm_earth_builder/incomplete.MQSPB6_0.0.1/mm_earth_builder-train.tfrecord*...:  46%|████▋     | 4650/10000 [00:02<00:02, 2360.93 examples/s]\n",
      "\u001b[Affling /home/admin/tensorflow_datasets/mm_earth_builder/incomplete.MQSPB6_0.0.1/mm_earth_builder-train.tfrecord*...:  73%|███████▎  | 7271/10000 [00:03<00:01, 2479.47 examples/s]\n",
      "\u001b[Affling /home/admin/tensorflow_datasets/mm_earth_builder/incomplete.MQSPB6_0.0.1/mm_earth_builder-train.tfrecord*...:  99%|█████████▉| 9904/10000 [00:04<00:00, 2537.86 examples/s]\n",
      "2025-02-22 20:37:57.340147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.392309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.392510: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.394820: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mm_earth_builder downloaded and prepared to /home/admin/tensorflow_datasets/mm_earth_builder/0.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.394964: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.395033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.631935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.632090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.632180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-22 20:37:57.632250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 24144 MB memory:  -> device: 0, name: NVIDIA L40-48Q, pci bus id: 0000:02:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': <_PrefetchDataset element_spec={'id': TensorSpec(shape=(), dtype=tf.string, name=None), 'sentinel1': TensorSpec(shape=(8, 64, 64), dtype=tf.float32, name=None), 'sentinel2': TensorSpec(shape=(12, 64, 64), dtype=tf.float32, name=None)}>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = MMEarthBuilder(modalities=MODALITIES)\n",
    "builder.download_and_prepare(\n",
    "    download_dir='/home/admin/john/data/mmearth_',\n",
    "    download_config=tfds.download.DownloadConfig(manual_dir='/home/admin/john/data/mmearth')\n",
    ")\n",
    "builder.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c060d-bb7c-4531-b38c-6537c30cfd9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
