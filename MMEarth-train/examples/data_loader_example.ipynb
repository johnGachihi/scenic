{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import torch\n",
    "\n",
    " \n",
    "# the custom dataset file also includes scripts for geobench. if you dont want that, simply comment out those lines. \n",
    "from mmearth_dataset import get_mmearth_dataloaders\n",
    "\n",
    "\n",
    "from MODALITIES import * # this contains all the input and output bands u need for pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args()\n",
    "\n",
    "# these 4 arguments need to be set manually\n",
    "args.data_path = '/data/mmearth/data_1M_v001/' # path to h5 file \n",
    "args.random_crop = True # ensure that if the dataset image size is 128 x 128, the resulting image after cropping is 112 x 112.\n",
    "args.random_crop_size = 112 # the size of the crop\n",
    "args.batch_size = 1\n",
    "\n",
    "# define the input and output bands for the dataset\n",
    "args.inp_modalities = INP_MODALITIES\n",
    "args.out_modalities = OUT_MODALITIES\n",
    "\n",
    "args.modalities = args.inp_modalities.copy()\n",
    "args.modalities.update(args.out_modalities) # args modalities is a dictionary of all the input and output bands.\n",
    "args.modalities_full = MODALITIES_FULL # this is a dictionary of all the bands in the dataset.\n",
    "\n",
    "args.no_ffcv = False # this flag allows you to load the ffcv dataloader or the h5 dataset.\n",
    "args.processed_dir = None # default is automatically created in the data path. this is the dir where the beton file for ffcv is stored\n",
    "args.num_workers = 4 # number of workers for the dataloader\n",
    "args.distributed = False # if you are using distributed training, set this to True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch): # only for non ffcv dataloader\n",
    "    # for each batch append the samples of the same modality together and return the ids. We keep track of the ids to differentiate between sentinel2_l1c and sentinel2_l2a\n",
    "    return_batch = {}\n",
    "    ids = [b['id'] for b in batch]\n",
    "    return_batch = {modality: torch.stack([b[modality] for b in batch], dim=0) for modality in args.modalities.keys()}\n",
    "    return ids, return_batch\n",
    "\n",
    "# the following line, creates a pytorch dataset object. \n",
    "if args.no_ffcv:\n",
    "    dataset = get_mmearth_dataloaders(\n",
    "        args.data_dir,\n",
    "        args.processed_dir, \n",
    "        args.modalities,\n",
    "        num_workers=args.num_workers,\n",
    "        batch_size_per_device=args.batch_size,\n",
    "        distributed=args.distributed\n",
    "    )[0] # non ffcv mode returns only the dataset object\n",
    "    \n",
    "    # define a sampler based on the number of tasks and the global rank. This is useful for distributed training\n",
    "    num_tasks = # number of tasks in distributed training\n",
    "    global_rank = # global rank of the current task\n",
    "    sampler_train = torch.utils.data.DistributedSampler(\n",
    "        dataset, num_replicas=num_tasks, rank=global_rank, shuffle=True, seed=args.seed,\n",
    "    )\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, sampler=sampler_train,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "else:\n",
    "    # if ffcv, we return the dataloader object\n",
    "    train_dataloader = get_mmearth_dataloaders(\n",
    "        args.data_dir,\n",
    "        args.processed_dir,\n",
    "        args.modalities,\n",
    "        num_workers=args.num_workers,\n",
    "        batch_size_per_device=args.batch_size,\n",
    "        distributed=args.distributed,\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataloader item is a dictionary of all the modalities.\n",
    "# this returns a dictionary of all the modalities as key, and the corresponding data as value. The keys \n",
    "# are similar to the ones in the args.modalities dictionary, or the MODALITIES.py file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
